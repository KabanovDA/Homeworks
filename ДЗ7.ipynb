{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SE67NfLFatLd",
    "outputId": "1146e694-3428-4c3f-accf-8e614cc398a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Danila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Danila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Danila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from tqdm import tqdm\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7EGRDcyKatLn"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for text in newsgroups_train.data:\n",
    "    tmp  = nltk.word_tokenize(text)\n",
    "    text = \" \".join([lemmatizer.lemmatize(w) for w in tmp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HeiX_SPLatLo"
   },
   "outputs": [],
   "source": [
    "features   = 4500\n",
    "components = 20\n",
    "top_words  = 10\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase    = True, \n",
    "                             stop_words   = _stop_words.ENGLISH_STOP_WORDS,\n",
    "                             analyzer     = 'word', \n",
    "                             binary       = True,\n",
    "                             max_df       = 0.95, \n",
    "                             min_df       = 2,\n",
    "                             max_features = features\n",
    ")\n",
    "# одновременно создали словарь и преобразовали строку в вектор\n",
    "train = vectorizer.fit_transform(newsgroups_train.data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VpP4u8nbatLp",
    "outputId": "46215065-0195-403b-d445-a1d000c97dd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HFi_tpPAatLr"
   },
   "outputs": [],
   "source": [
    "class customLDA:\n",
    "    def __init__(self, components=10, alpha=None, beta=None, max_iter=50):\n",
    "        self._components = components\n",
    "        self._alpha      = alpha\n",
    "        self._beta       = beta\n",
    "        self._max_iter   = max_iter\n",
    "                \n",
    "        self._cnt_k = None    # колво слов в теге k по всем документам\n",
    "        self._cnt_w = None    # колво раз сколько слово w было в теге k\n",
    "        self._cnt_d = None    # количество вхождений тега k в документе d\n",
    "\n",
    "        self._fit_Is = False\n",
    "\n",
    "    def fit(self, main_matrix):\n",
    "        self._cnt_k  = np.zeros(self._components)                                  \n",
    "        self._cnt_w = np.zeros((self._components, main_matrix.shape[1]))          \n",
    "        self._cnt_d = np.zeros((main_matrix.shape[0], self._components))         \n",
    "\n",
    "        if self._alpha == None:  self._alpha = np.ones(self._components)\n",
    "        if self._beta  == None:  self._beta  = np.ones(main_matrix.shape[1])\n",
    "\n",
    "        documn_, word_ =  main_matrix.nonzero()\n",
    "        z = np.random.choice(self._components, len(documn_))\n",
    "\n",
    "        for i,j,k in zip(documn_, word_, z):\n",
    "            self._cnt_k[k]    += 1\n",
    "            self._cnt_w[k, j] += 1\n",
    "            self._cnt_d[i, k] += 1\n",
    "        \n",
    "        for i in tqdm(range(self._max_iter)):\n",
    "            for j in range(len(documn_)):\n",
    "                current_word = word_[j]\n",
    "                current_dc   = documn_[j]\n",
    "                current_tag  = z[j]\n",
    "                self._cnt_d[current_dc, current_tag] -= 1\n",
    "                self._cnt_w[current_tag, current_word] -= 1\n",
    "                self._cnt_k[current_tag] -= 1\n",
    "                p = (self._cnt_d[current_dc, :] + self._alpha) * (self._cnt_w[:, current_word] + self._beta[current_word]) / (self._cnt_k + self._beta.sum())\n",
    "                z[j] = np.random.choice(self._components, p = p / p.sum())\n",
    "                self._cnt_d[current_dc, z[j]] += 1\n",
    "                self._cnt_w[z[j], current_word] += 1\n",
    "                self._cnt_k[z[j]] += 1\n",
    "        \n",
    "        self._fit_Is = True\n",
    "        return self\n",
    "    \n",
    "    def get_table_tags_and_word(self):\n",
    "        if self._fit_Is:\n",
    "            return self._cnt_w\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7EtR_NQatLt",
    "outputId": "958fe2b7-4194-43c4-94b8-0ec1c93e22a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [16:12<00:00, 19.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.customLDA at 0x2593c40a790>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = customLDA(components, max_iter=50)\n",
    "lda.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zq6OvkC_atLu",
    "outputId": "efd04202-0369-4bec-c795-b89178636a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag 1 \tdoes\tdon\tedu\tgood\tjust\tknow\tlike\tsoon\tve\twork\n",
      "Tag 2 \tbelieve\tbible\tchristian\tdoes\tfact\tgod\tjesus\tpeople\tsay\ttrue\n",
      "Tag 3 \tbetter\tdon\tgoing\tgood\tlike\tmake\tthink\ttime\tve\twant\n",
      "Tag 4 \tcard\tdisk\tdrive\thard\tnew\tpc\tsale\tsoftware\tuse\tvideo\n",
      "Tag 5 \tgovernment\thistory\tlaw\tmilitary\tpeople\trights\tstate\tstates\twar\tworld\n",
      "Tag 6 \tdoes\thelp\thi\tknow\tproblem\tprogram\tthanks\tuse\tusing\twindows\n",
      "Tag 7 \tdoes\tdon\tjust\tknow\tlike\tpeople\tright\tsay\tthink\tway\n",
      "Tag 8 \tcurrent\thigh\tlarge\tlow\tpower\tuse\tused\tusing\tway\twork\n",
      "Tag 9 \tcame\tday\tdid\tgot\told\tsaid\tsaw\tstarted\ttold\twent\n",
      "Tag 10 \tbike\tcar\tcars\tengine\tgood\tjust\tlike\tlittle\tnew\troad\n",
      "Tag 11 \t1993\tapril\tearth\tinformation\tnasa\tnational\tresearch\tscience\tspace\tuniversity\n",
      "Tag 12 \tchip\tclipper\tencryption\tgovernment\tkey\tkeys\tphone\tpublic\tuse\tusing\n",
      "Tag 13 \tdon\tgood\tjust\tknow\tlike\treally\tsaid\tthing\tthink\tve\n",
      "Tag 14 \tago\tjust\tlook\tmake\tmoney\tnew\tpay\ttime\tyear\tyears\n",
      "Tag 15 \tcase\tcause\tcertain\tcommon\teffect\tpeople\tquestion\tsimilar\tuse\tusually\n",
      "Tag 16 \t10\t11\t12\t13\t14\t15\t16\t20\t24\t25\n",
      "Tag 17 \tavailable\tcode\tedu\tfile\tftp\tmit\tpub\tsource\tuser\tversion\n",
      "Tag 18 \tcase\tdid\tjust\tknow\tlet\tpeople\tright\tsaid\tsay\tthink\n",
      "Tag 19 \tarticle\tcom\tedu\tknow\tlike\tlist\tmail\tpost\tread\tsend\n",
      "Tag 20 \tgame\tgames\tgood\tleague\tplay\tplayers\tseason\tteam\twin\tyear\n"
     ]
    }
   ],
   "source": [
    "result = np.argsort(lda.get_table_tags_and_word(), axis=1)[:, -top_words:]\n",
    "\n",
    "for i in range(components):\n",
    "    matrix = np.zeros((1, train.shape[1]))\n",
    "    for j in result[i]:\n",
    "        matrix[0, j] = 1\n",
    "    print('Tag {} \\t{}'.format(i + 1, '\\t'.join(vectorizer.inverse_transform(matrix)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
